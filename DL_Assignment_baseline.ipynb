{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xveQIshNWYdc"
   },
   "source": [
    "# Loading Dataset\n",
    "\n",
    "You can download the dataset from {https://darwin.v7labs.com/v7-labs/covid-19-chest-x-ray-dataset?sort=priority\\%3Adesc}.\n",
    "The data entitled as '`darwin dataset pull v7-labs/covid-19-chest-x-ray-dataset:all-images`' will be used in this assignment. All dataset consist of 6504 images from 702 classes. We will extract the images of 4 classes (Bacterial Pneumonia, Viral Pneumonia, No Pneumonia (healthy), Covid-19) and save them as .npy file with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "I6bqTVRSs-sw",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 11:27:27.823421: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-26 11:27:28.126856: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-26 11:27:28.126881: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-26 11:27:29.529532: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-26 11:27:29.529686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-26 11:27:29.529696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "from keras import layers, models\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn import preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nContinue working in next cell\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################\n",
    "# > DISABLED - ALREADY EXECUTED < #\n",
    "###################################\n",
    "\n",
    "'''\n",
    "Continue working in next cell\n",
    "'''\n",
    "\n",
    "# # all-images file should be uploaded to the same file\n",
    "# imageNames = glob.glob(\"all-images/*\")\n",
    "# \n",
    "# dataset = []\n",
    "# labels = []\n",
    "# \n",
    "# for i, imName in enumerate(imageNames):\n",
    "# \n",
    "#     # Opening JSON file\n",
    "#     f = open(imName)\n",
    "#     data = json.load(f)\n",
    "#     for j in range(len(data['annotations'])):\n",
    "# \n",
    "#         if 'COVID-19' in (data['annotations'][j]['name']):\n",
    "#           #load images from url    \n",
    "#             urllib.request.urlretrieve(data['image']['url'],\"img.png\")    \n",
    "#             img = Image.open(\"img.png\")\n",
    "#             #convert images to grayscale\n",
    "#             imgGray = img.convert('L')\n",
    "#             #resize the image (156x156)\n",
    "#             im = imgGray.resize((156,156), Image.LANCZOS)           \n",
    "#             label = data['annotations'][j]['name']\n",
    "#             dataset.append(np.array(im))\n",
    "#             labels.append(label)\n",
    "#             print(label)\n",
    "#             break\n",
    "# \n",
    "#         if 'Viral Pneumonia' in (data['annotations'][j]['name']) \\\n",
    "#             or 'Bacterial Pneumonia' in (data['annotations'][j]['name']) \\\n",
    "#             or 'No Pneumonia (healthy)' in (data['annotations'][j]['name']):\n",
    "#             #load images from url    \n",
    "#             urllib.request.urlretrieve(data['image']['url'],\"img.png\")    \n",
    "#             img = Image.open(\"img.png\")\n",
    "#             #convert images to grayscale\n",
    "#             imgGray = img.convert('L')\n",
    "#             #resize the image (156x156)\n",
    "#             im = imgGray.resize((156,156), Image.LANCZOS)           \n",
    "#             label = data['annotations'][j]['name']\n",
    "#             dataset.append(np.array(im))\n",
    "#             labels.append(label)\n",
    "#             break\n",
    "# \n",
    "# #Convert data shape of (n_of_samples, width, height, 1)\n",
    "# dataset = np.dstack(dataset)    \n",
    "# dataset = np.rollaxis(dataset,-1)\n",
    "# labels = np.array(labels)\n",
    "# \n",
    "# #convert images gray scale to rgb\n",
    "# data = np.array(layers.Lambda(tf.image.grayscale_to_rgb)(tf.expand_dims(dataset, -1)))\n",
    "# \n",
    "# # save data and labels into a folder\n",
    "# np.save(\"data.npy\", data)\n",
    "# np.save(\"labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dn3sH7yJWboe"
   },
   "source": [
    "Once you save your data, you can load it from your directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b6ZPDhVLWbyq"
   },
   "outputs": [],
   "source": [
    "data = np.load('data/data.npy')\n",
    "labels = np.load('data/labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1b7dP-VbJpC"
   },
   "source": [
    "# Preprocessing Steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xC_YmdQMbn1K"
   },
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xStbdJAHblFv"
   },
   "outputs": [],
   "source": [
    "# stratify?\n",
    "# shuffle?\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-r4ta3MbKLJ"
   },
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeplL77mbKS4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YONVgtOAbKca"
   },
   "source": [
    "# Create Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LhUlV9UNbKiH"
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# > BY CHAT GPT < #\n",
    "####################\n",
    "\n",
    "# define sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# 1st conv layer\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(img_height, img_width, num_channels)))\n",
    "# 2nd conv layer\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "# 1st pooling layer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# add conv and pol layers block twice\n",
    "for _ in range(2):\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# add dense layers with ReLu\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "# add output layer with softmax \n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# compile the model, loss, optimizer and metrics\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "model.summary()\n",
    "\n",
    "# train model with selected data\n",
    "model.fit(train_data, epochs=10, batch_size=32, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOFuKRShbvTU"
   },
   "source": [
    "# Analyze the performance of the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58gf79ODcFPD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnxtO6BIb3_P"
   },
   "source": [
    "# Adapting/fine-tuning the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oiDja0Mub4YW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBGr0x8ZcFn9"
   },
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fn_WnCfDcFyD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
